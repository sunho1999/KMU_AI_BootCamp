{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic DNN for MNIST",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwNHiq5UtvWt"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn0YzobLxwRp"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # GPU 객체 선언"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7DBs6GZuou3"
      },
      "source": [
        "# MNIST 데이터 셋 불러오기\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 64 # 배치 사이즈 설정\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdp1Xcx2uz2P"
      },
      "source": [
        "# 임의의 이미지 분류 딥 뉴럴 네트워크 선언\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.l1 = nn.Linear(784, 480) # 입력 크기: 784 차원(픽셀)\n",
        "        self.l2 = nn.Linear(480, 200)\n",
        "        self.l3 = nn.Linear(200, 80)\n",
        "        self.l4 = nn.Linear(80, 10) # 10개로 분류 (출력층)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)  # (배치 사이즈, 1, 28, 28) 크기의 데이터를 (배치 사이즈, 784) 형태로 변경\n",
        "        x = F.relu(self.l1(x))\n",
        "        x = F.relu(self.l2(x))\n",
        "        x = F.relu(self.l3(x))\n",
        "        return self.l4(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPlo3q9pvbOu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "cd1d7196-dd32-4a8b-dee7-9c8c663c0fd7"
      },
      "source": [
        "model = Net().to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (l1): Linear(in_features=784, out_features=480, bias=True)\n",
            "  (l2): Linear(in_features=480, out_features=200, bias=True)\n",
            "  (l3): Linear(in_features=200, out_features=80, bias=True)\n",
            "  (l4): Linear(in_features=80, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyYFcN-qvqrs"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss() # 손실 함수 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.2) # 최적화 함수\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step() # 모델 가중치 업데이트\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.8f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o33WxzdlxCk3"
      },
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        loss += criterion(output, target).data.item()\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "    loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tbjbi5fwuro",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80f7e420-0aa3-43c7-d81c-61e04bcf7945"
      },
      "source": [
        "for epoch in range(1, 11):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.29973841\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.30202866\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.28362989\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.26434207\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.24318957\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.20229530\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.13752699\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.97874355\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.71705973\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.46533930\n",
            "\n",
            "Test set: Average loss: 0.0192, Accuracy: 6894/10000 (69%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.09499383\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.90491831\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.98894066\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.62206197\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.58444732\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.41077390\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.67227507\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.50685823\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.45321539\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.57340497\n",
            "\n",
            "Test set: Average loss: 0.0070, Accuracy: 8714/10000 (87%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.47672641\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.36490798\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.51761222\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.42377043\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.34483901\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.41745582\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.43669343\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.62508625\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.39678991\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.44428077\n",
            "\n",
            "Test set: Average loss: 0.0055, Accuracy: 8937/10000 (89%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.26219860\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.35712850\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.43690401\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.45992917\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.22395371\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.26992360\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.32383415\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.29488501\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.35318545\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.38152912\n",
            "\n",
            "Test set: Average loss: 0.0049, Accuracy: 9073/10000 (91%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.34155259\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.40807134\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.30143169\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.33902788\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.23149955\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.35203907\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.18336138\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.13821264\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.38005486\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.39012006\n",
            "\n",
            "Test set: Average loss: 0.0041, Accuracy: 9236/10000 (92%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.24993780\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.26940361\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.08142281\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.15988955\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.18102130\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.27507901\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.20094967\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.13680774\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.17475218\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.24743187\n",
            "\n",
            "Test set: Average loss: 0.0035, Accuracy: 9347/10000 (93%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.22317824\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.17254603\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.29148030\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.21171156\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.16588198\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.17398901\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.12150305\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.09210128\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.10203900\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.21484584\n",
            "\n",
            "Test set: Average loss: 0.0032, Accuracy: 9399/10000 (94%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.20830709\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.17629351\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.20370726\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.27614355\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.10683157\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.15236372\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.19275370\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.24479827\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.32506037\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.10904197\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 9479/10000 (95%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.17300749\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.09649712\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.11818295\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.07012740\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.19670245\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.20147036\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.21009645\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.13933472\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.20850025\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.27678251\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy: 9479/10000 (95%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.21618526\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.17466922\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.15113413\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.41156551\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.15017425\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.24305400\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.05643795\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.21419187\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.06198971\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.16583478\n",
            "\n",
            "Test set: Average loss: 0.0024, Accuracy: 9543/10000 (95%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW6_Dwkov68R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "452e0b9b-0613-4b20-a056-b224da79cfd9"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_data = test_dataset[0][0].to(device)\n",
        "image_label = test_dataset[0][1]\n",
        "print('숫자 이미지 X의 크기:', image_data.size())\n",
        "print('숫자 이미지 X의 레이블:', image_label)\n",
        "print(model(image_data))\n",
        "plt.imshow(image_data.cpu().numpy()[0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "숫자 이미지 X의 크기: torch.Size([1, 28, 28])\n",
            "숫자 이미지 X의 레이블: 7\n",
            "tensor([[  1.2270,  -2.3440,   3.4852,   5.0390,  -5.9945,  -0.8671, -10.7527,\n",
            "          10.6472,  -0.4550,   1.7571]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fac93473898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}